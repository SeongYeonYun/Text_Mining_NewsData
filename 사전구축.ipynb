{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"korean_air_2020_01.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_02.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_03.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_04.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_05.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_6.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_07.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_08.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_09.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_10.csv\")\n",
    "\n",
    "#data = pd.concat([first, second, third, fourth, fifth, sixth])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data.columns = [\"a\",\"title\",\"text\",\"repoter\",\"spon\", \"date\"]\n",
    "date = data.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q불용어 지정\n",
    "#기자이름\n",
    "repoter = data[\"repoter\"].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신문사 이름\n",
    "spon = data[\"spon\"].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "#대표적인 조사\n",
    "stopwords = ['의','가','이','권','은','들','는','좀','잘','걍','과','도','을','것','를','등','으로','자','에','등','와','한','하다''것','로']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 병합\n",
    "stopwords.extend(data.repoter.values)\n",
    "stopwords.extend(data.spon.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "432"
      ]
     },
     "execution_count": 472,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 8592\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 4133\n",
      "단어 집합에서 희귀 단어의 비율: 48.10288640595903\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.481598379020788\n",
      "단어 집합의 크기 : 4459\n"
     ]
    }
   ],
   "source": [
    "# 한글 외의 모든 데이터 제거 : 기업명이 영어로 되어있는 경우를 어떻게 처리 해야할까?\n",
    "data = data.text.str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "okt = Okt()\n",
    "X_train = []\n",
    "X_train2 =[]\n",
    "\n",
    "for sen in data :\n",
    "    temp_X = []\n",
    "    \n",
    "    # 토큰화\n",
    "    temp_X = okt.morphs(sen, stem = True) \n",
    "    \n",
    "    # 불용어 제거\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] \n",
    "    \n",
    "    #모든 토큰들을 리스트에 기사별로 저장\n",
    "    X_train.append(temp_X)\n",
    "    \n",
    "    #모든 토큰들을  하나의 리스트에 저장\n",
    "    X_train2.extend(temp_X)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "threshold = 3\n",
    "total_cnt = len(tokenizer.word_index) # 단어의 수\n",
    "rare_cnt = 0 # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "total_freq = 0 # 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "rare_freq = 0 # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt / total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq / total_freq)*100)\n",
    "\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "vocab_size = total_cnt - rare_cnt\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#요일 구하기\n",
    "import datetime\n",
    "def getDayName(a):\n",
    "        D = a.split(\"/\")\n",
    "        y = int(D[0])\n",
    "        m = int(D[1])\n",
    "        d = int(D[2])\n",
    "        return ['MON','TUE','WED','THU','FRI','SAT','SUN'][datetime.date(y,m,d).weekday()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday =[]\n",
    "for x in date:\n",
    "    weekday.append(getDayName(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = date.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2020/01/31', '2020/01/30', '2020/01/29', '2020/01/28', '2020/01/27', '2020/01/26', '2020/01/25', '2020/01/24', '2020/01/23', '2020/01/22', '2020/01/21', '2020/01/20', '2020/01/19', '2020/01/18', '2020/01/17', '2020/01/16', '2020/01/15', '2020/01/14', '2020/01/13', '2020/01/12', '2020/01/11', '2020/01/10', '2020/01/09', '2020/01/08', '2020/01/07', '2020/01/06', '2020/01/05', '2020/01/01']\n"
     ]
    }
   ],
   "source": [
    "DATE = []\n",
    "for x in date:\n",
    "    if x not in DATE:\n",
    "        DATE.append(x)\n",
    "print(DATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "#증감 데이터 불러오기\n",
    "increase_r = pd.read_csv(\"대비처리.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase = increase_r[[\"년/월/일\",\"증감\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_frame = pd.DataFrame( {\"date\" : date,\"weekday\" : weekday})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    " for x in range(0,len(weekday_frame)):\n",
    "    if weekday_frame.weekday[x] == \"SAT\":\n",
    "        monday = DATE.index(weekday_frame.date[x])- 2\n",
    "        weekday_frame.date[x] = DATE[monday]\n",
    "        weekday_frame.weekday[x] == \"MON\"\n",
    "            \n",
    "    else :\n",
    "        if weekday_frame.weekday[x] == \"SUN\":\n",
    "            monday = DATE.index(weekday_frame.date[x]) - 1\n",
    "            weekday_frame.date[x] = DATE[monday]\n",
    "            weekday_frame.weekday[x] == \"MON\"\n",
    "                \n",
    "        else : pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2020/01/31', '2020/01/30', '2020/01/29', '2020/01/28',\n",
       "       '2020/01/27', '2020/01/24', '2020/01/23', '2020/01/22',\n",
       "       '2020/01/21', '2020/01/20', '2020/01/17', '2020/01/16',\n",
       "       '2020/01/15', '2020/01/14', '2020/01/13', '2020/01/10',\n",
       "       '2020/01/09', '2020/01/08', '2020/01/07', '2020/01/06',\n",
       "       '2020/01/01'], dtype=object)"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weekday_frame.date.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_frame = weekday_frame.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_frame.to_csv(\"weekday.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날자를 중심으로 데이터 병합\n",
    "increase = increase.rename(columns ={ \"년/월/일\" : \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frame = pd.DataFrame({\"data\" : X_train, \"date\" : date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase2 = pd.merge(weekday_frame, increase , on = \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del increase2[\"weekday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase2 = increase2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frame2 = pd.merge( dic_frame, increase2, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dic_frame2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딕셔너리 key 생성\n",
    "key_list = []\n",
    "for v in X_train2:\n",
    "    if v not in key_list:\n",
    "        key_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예상 소요 시간 300분\n",
    "#사전 만들기\n",
    "dictionary = {\"<UNK>\" : { \"횟수\" : 0, \"점수\" : 0, \"극성정도\" : 0}}\n",
    "\n",
    "for k in key_list:  #키 리스트안에 있는 단어가 언급이 되는 경우\n",
    "    count = 0\n",
    "    score = 0\n",
    "    for x in range(0,len(dic)):  #한 기사씩 검사한다.\n",
    "        d = dic.loc[x,:].data\n",
    "        \n",
    "        \n",
    "        #count 는 전체 언급된 횟수, score는 증감의 총합, pority는 총합의 평균\n",
    "        if k in d:            \n",
    "            count = count + d.count(k)\n",
    "            score = score + (dic.loc[x,:][\"증감\"] * d.count(k))\n",
    "        \n",
    "       \n",
    "        #elif k not in word_list:\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    polarity  = score/count\n",
    "    dictionary[k] = { \"횟수\" : count, \"점수\" : score, \"극성정도\" : polarity}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "227 미온\n"
     ]
    }
   ],
   "source": [
    "#기사별 점수 계산\n",
    "\n",
    "from collections import Counter\n",
    "scores = []\n",
    "for x in range (0, len(dic)):\n",
    "    key = set(dic.data[x])\n",
    "    score = 0\n",
    "    count = 0\n",
    "    for i in key:\n",
    "        score += (dictionary[i][\"극성정도\"] * Counter(dic.data[x])[i])\n",
    "        count += Counter(dic.data[x])[i]\n",
    "    try :\n",
    "        score = score/count\n",
    "        scores.append(score)\n",
    "        \n",
    "    except ZeroDivisionError as e:\n",
    "        print(x,k)\n",
    "        mis = x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거\n",
    "dic.drop([mis], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic[\"score\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날자별 점수 평균계산\n",
    "score_data = dic.groupby(['date'])[\"score\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날자별 평균 데이터 저장\n",
    "score_data.to_csv(\"score_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "daehan_06 = dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딕셔너리 저장\n",
    "# save data\n",
    "\n",
    "with open('daehan_06.pickle','wb') as fw:\n",
    "    pickle.dump(daehan_06, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
