{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from konlpy.tag import Okt\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#data = pd.read_csv(\"korean_air_2020_01.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_02.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_03.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_04.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_05.csv\")\n",
    "#data = pd.read_csv(\"korean_air_2020_6.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_07.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_08.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_09.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_korean_air_2020_10.csv\")\n",
    "#data = pd.read_csv(\"korean_air_data_11~12.csv\")\n",
    "\n",
    "#data = pd.read_csv(\"naver_2020_1.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_2.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_3.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_4.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_5.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_6.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_7.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_8.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_9.csv\")\n",
    "#data = pd.read_csv(\"naver_2020_10.csv\")\n",
    "\n",
    "data = pd.read_csv(\"lg_chem_2020_01.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_02.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_03.csv\")\n",
    "\n",
    "#data = pd.read_csv(\"lg_chem_2020_04.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_05.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_06.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_07.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_08.csv\")\n",
    "\n",
    "#data = pd.read_csv(\"lg_chem_2020_09.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_10.csv\")\n",
    "#data = pd.read_csv(\"lg_chem_2020_11~12.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna()\n",
    "data.columns = [\"a\",\"title\",\"text\",\"repoter\",\"spon\", \"date\"]\n",
    "date = data.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q불용어 지정\n",
    "#기자이름\n",
    "repoter = data[\"repoter\"].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "#신문사 이름\n",
    "spon = data[\"spon\"].unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "#대표적인 조사\n",
    "stopwords = ['의','가','이','권','은','들','는','좀','잘', \\\n",
    "             '걍','과','도','을','것','를','등','으로','자',\\\n",
    "             '에','등','와','한','하다''것','로']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "#불용어 병합\n",
    "stopwords.extend(data.repoter.values)\n",
    "stopwords.extend(data.spon.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합(vocabulary)의 크기 : 8235\n",
      "등장 빈도가 2번 이하인 희귀 단어의 수: 3956\n",
      "단어 집합에서 희귀 단어의 비율: 48.03885853066181\n",
      "전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 3.6091794158553547\n",
      "단어 집합의 크기 : 4279\n"
     ]
    }
   ],
   "source": [
    "# 한글 외의 모든 데이터 제거\n",
    "data = data.text.str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\",\"\")\n",
    "\n",
    "\n",
    "okt = Okt()\n",
    "X_train = []\n",
    "X_train2 = []\n",
    "\n",
    "for sen in data :\n",
    "    temp_X = []\n",
    "    \n",
    "    # 토큰화\n",
    "    temp_X = okt.morphs(sen, stem = True) \n",
    "    \n",
    "    # 불용어 제거\n",
    "    temp_X = [word for word in temp_X if not word in stopwords] \n",
    "    \n",
    "    #모든 토큰들을 리스트에 기사별로 저장\n",
    "    X_train.append(temp_X)\n",
    "    \n",
    "    #모든 토큰들을  하나의 리스트에 저장\n",
    "    X_train2.extend(temp_X)\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "threshold = 3\n",
    "\n",
    "# 단어의 수\n",
    "total_cnt = len(tokenizer.word_index)\n",
    "\n",
    "# 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n",
    "rare_cnt = 0 \n",
    "\n",
    "# 훈련 데이터의 전체 단어 빈도수 총 합\n",
    "total_freq = 0 \n",
    "\n",
    "# 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총합\n",
    "rare_freq = 0 \n",
    "\n",
    "# 단어와 빈도수의 쌍(pair)을 key와 value로 받는다.\n",
    "for key, value in tokenizer.word_counts.items():\n",
    "    total_freq = total_freq + value\n",
    "\n",
    "    # 단어의 등장 빈도수가 threshold보다 작으면\n",
    "    if(value < threshold):\n",
    "        rare_cnt = rare_cnt + 1\n",
    "        rare_freq = rare_freq + value\n",
    "\n",
    "print('단어 집합(vocabulary)의 크기 :',total_cnt)\n",
    "print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s'%(threshold - 1, rare_cnt))\n",
    "print(\"단어 집합에서 희귀 단어의 비율:\", (rare_cnt/total_cnt)*100)\n",
    "print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율:\", (rare_freq/total_freq)*100)\n",
    "\n",
    "# 전체 단어 개수 중 빈도수 2이하인 단어 개수는 제거.\n",
    "vocab_size = total_cnt - rare_cnt\n",
    "print('단어 집합의 크기 :',vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "nouns = []\n",
    "str = ''\n",
    "\n",
    "for k in range(0,len(X_train)):\n",
    "    for i in range(0,len(X_train[k])):\n",
    "        str = str + X_train[k][i] + ' '\n",
    "    nouns.append(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_df = pd.DataFrame()\n",
    "\n",
    "tfIdfVectorizer = TfidfVectorizer(use_idf=True)\n",
    "tfidf = tfIdfVectorizer.fit_transform(nouns)\n",
    "\n",
    "for i in range(0,len(X_train)):\n",
    "    df = pd.DataFrame(tfidf[i].T.toarray(), \\\n",
    "                      index=tfIdfVectorizer.get_feature_names(), \\\n",
    "                      columns=[\"text{}\".format(i)])\n",
    "    tfidf_df = pd.concat([tfidf_df,df],axis = 1)\n",
    "\n",
    "X_train_tfidf = []\n",
    "X_train_tfidf2 = []\n",
    "\n",
    "for i in range(0,len(X_train)):\n",
    "    idx = tfidf_df['text{}'.format(i)] > 0.01\n",
    "    result = tfidf_df[idx].index.tolist()\n",
    "    X_train_tfidf.append(result)\n",
    "    X_train_tfidf2.extend(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#요일 구하기\n",
    "date2 = []\n",
    "weekday = []\n",
    "\n",
    "for x in date:\n",
    "    x = x.replace(\"-\",\"/\")\n",
    "    D = x.split(\"/\")\n",
    "    y = int(D[0])\n",
    "    y_string = D[0]\n",
    "    if len(D[1]) < 2 :\n",
    "        D[1] = \"0\" + D[1]\n",
    "        m = int(D[1])\n",
    "        m_string = D[1]\n",
    "        \n",
    "    else : \n",
    "        m = int(D[1])\n",
    "        m_string = D[1]\n",
    "    \n",
    "    if len(D[2]) < 2 :\n",
    "        D[2] = \"0\" + D[2]\n",
    "        d = int(D[1])\n",
    "        d_string = D[2]\n",
    "        \n",
    "    else : \n",
    "        d = int(D[2])\n",
    "        d_string = D[2]\n",
    "        \n",
    "    date2.append(y_string + \"/\" + m_string + \"/\" + d_string)\n",
    "    weekday.append(['MON','TUE','WED','THU','FRI','SAT','SUN']\\\n",
    "                   [datetime.date(y,m,d).weekday()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = date2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATE = []\n",
    "\n",
    "for x in date:\n",
    "    if x not in DATE:\n",
    "        DATE.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "#증감 데이터 불러오기\n",
    "increase_r = pd.read_csv(\"LG화학 대비처리.csv\")\n",
    "#increase_r = pd.read_csv(\"대한항공 대비처리.csv\")\n",
    "#increase_r = pd.read_csv(\"naver 대비처리.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase = increase_r[[\"년/월/일\",\"증감\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_frame = pd.DataFrame( {\"date\": date, \"weekday\": weekday})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(0,len(weekday_frame)):\n",
    "    if weekday_frame.weekday[x] == \"SAT\":\n",
    "        monday = DATE.index(weekday_frame.date[x]) - 2\n",
    "        weekday_frame.date[x] = DATE[monday]\n",
    "        weekday_frame.weekday[x] == \"MON\"\n",
    "            \n",
    "    else :\n",
    "        if weekday_frame.weekday[x] == \"SUN\":\n",
    "            monday = DATE.index(weekday_frame.date[x]) - 1\n",
    "            weekday_frame.date[x] = DATE[monday]\n",
    "            weekday_frame.weekday[x] == \"MON\"\n",
    "                \n",
    "        else : pass\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekday_frame = weekday_frame.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weekday_frame.to_csv(\"weekday_naver.csv\")\n",
    "#weekday_frame.to_csv(\"weekday_daehan.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날자를 중심으로 데이터 병합\n",
    "increase = increase.rename(columns = {\"년/월/일\" : \"date\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frame = pd.DataFrame({\"data\" : X_train_tfidf, \"date\" : date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase2 = pd.merge(weekday_frame, increase , on = \"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "del increase2[\"weekday\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "increase2 = increase2.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_frame2 = pd.merge(dic_frame, increase2, on = \"date\", how = \"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic = dic_frame2.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딕셔너리 key 생성\n",
    "#key_list = []\n",
    "\n",
    "#for v in X_train_tfidf2:\n",
    "#    if v not in key_list:\n",
    "#        key_list.append(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#예상 소요 시간 300분\n",
    "#사전 만들기\n",
    "#dictionary = {\"<UNK>\": {\"횟수\": 0, \"점수\": 0, \"극성정도\": 0}}\n",
    "\n",
    "#for k in key_list:  #키 리스트안에 있는 단어가 언급이 되는 경우\n",
    "#    count = 0\n",
    "#    score = 0\n",
    "#    for x in range(0,len(dic)):  #한 기사씩 검사한다.\n",
    "#        d = dic.loc[x,:].data\n",
    "        \n",
    "        \n",
    "        #count 는 전체 언급된 횟수,score는 증감의 총합,pority는 총합의 평균\n",
    "#        if k in d:\n",
    "#            count = count + d.count(k)\n",
    "#            score = score + (dic.loc[x,:][\"증감\"] * d.count(k))\n",
    "               \n",
    "#        else:\n",
    "            \n",
    "#            pass\n",
    "        \n",
    "#    try:\n",
    "        \n",
    "#        polarity  = score/count\n",
    "        \n",
    "#    except ZeroDivisionError as e:\n",
    "        \n",
    "#        print(x,k)\n",
    "        \n",
    "#    dictionary[k] = {\"횟수\" : count, \"점수\" : score, \"극성정도\" : polarity}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#딕셔너리 저장\n",
    "#with open('lg_chem_10','wb') as fw:\n",
    "#    pickle.dump(dictionary, fw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#최종 dic계산\n",
    "with open('daehan_fin.pickle', 'rb') as f:\n",
    "    daehan = pickle.load(f)\n",
    "with open('lg_chem_fin.pickle', 'rb') as f:\n",
    "    lg_chem = pickle.load(f)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [],
   "source": [
    "#기사별 점수 계산\n",
    "scores = []\n",
    "miss = []\n",
    "for x in range (0, len(dic)):\n",
    "    key = set(dic.data[x])\n",
    "    score = 0\n",
    "    count = 0\n",
    "    \n",
    "    for i in key:\n",
    "        count += Counter(dic.data[x])[i]\n",
    "        \n",
    "    try:    \n",
    "            \n",
    "        score += (daehan[i][\"극성정도\"] * Counter(dic.data[x])[i])\n",
    "        score = score/count\n",
    "        scores.append(score)\n",
    "            \n",
    "    except KeyError :\n",
    "        \n",
    "        score += 0\n",
    "        score = score/count\n",
    "        scores.append(score)\n",
    "        \n",
    "        \n",
    "        \n",
    "    except ZeroDivisionError :\n",
    "        \n",
    "        print(x,k)\n",
    "        miss.append(x)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "390"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거\n",
    "dic.drop(miss, inplace = True)\n",
    "dic[\"score\"] = scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 538,
   "metadata": {},
   "outputs": [],
   "source": [
    "#날자별 점수 평균계산\n",
    "score_data = dic.groupby(['date'])[\"score\"].mean()\n",
    "\n",
    "#날자별 평균 데이터 저장\n",
    "score_data.to_csv(\"lg_chem_1_score.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [],
   "source": [
    "#알람\n",
    "winsound.PlaySound(\"SystemExit\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 542,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>date</th>\n",
       "      <th>증감</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[계약, 공급, 공식, 공장, 글로벌, 기록, 기자, 까지, 나오다, 난징, 넘어서...</td>\n",
       "      <td>2020/01/31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[계약, 공급, 공식, 공장, 규모, 글로벌, 기록, 기자, 까지, 나오다, 난징,...</td>\n",
       "      <td>2020/01/31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[가량, 가치, 경제, 계약, 공급, 공식, 공장, 과는, 국내, 규모, 그간, 글...</td>\n",
       "      <td>2020/01/31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[가량, 가치, 각각, 강세, 같다, 개인, 거래, 경제, 계약, 공급, 공식, 공...</td>\n",
       "      <td>2020/01/31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.001861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[가능성, 가량, 가운데, 가치, 각각, 감안, 감염, 감염증, 강세, 같다, 개국...</td>\n",
       "      <td>2020/01/31</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.000937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>[가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, 개발, ...</td>\n",
       "      <td>2020/01/02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>386</th>\n",
       "      <td>[가격, 가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, ...</td>\n",
       "      <td>2020/01/02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>[가격, 가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, ...</td>\n",
       "      <td>2020/01/02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>[가격, 가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, ...</td>\n",
       "      <td>2020/01/02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>[가격, 가능성, 가다, 가동, 가장, 가치, 각각, 감소, 강세, 강조, 강화, ...</td>\n",
       "      <td>2020/01/01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.007576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>390 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  data        date   증감  \\\n",
       "0    [계약, 공급, 공식, 공장, 글로벌, 기록, 기자, 까지, 나오다, 난징, 넘어서...  2020/01/31 -1.0   \n",
       "1    [계약, 공급, 공식, 공장, 규모, 글로벌, 기록, 기자, 까지, 나오다, 난징,...  2020/01/31 -1.0   \n",
       "2    [가량, 가치, 경제, 계약, 공급, 공식, 공장, 과는, 국내, 규모, 그간, 글...  2020/01/31 -1.0   \n",
       "3    [가량, 가치, 각각, 강세, 같다, 개인, 거래, 경제, 계약, 공급, 공식, 공...  2020/01/31 -1.0   \n",
       "4    [가능성, 가량, 가운데, 가치, 각각, 감안, 감염, 감염증, 강세, 같다, 개국...  2020/01/31 -1.0   \n",
       "..                                                 ...         ...  ...   \n",
       "385  [가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, 개발, ...  2020/01/02  0.0   \n",
       "386  [가격, 가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, ...  2020/01/02  0.0   \n",
       "387  [가격, 가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, ...  2020/01/02  0.0   \n",
       "388  [가격, 가능성, 가다, 가동, 가장, 각각, 감소, 강세, 강조, 강화, 같다, ...  2020/01/02  0.0   \n",
       "389  [가격, 가능성, 가다, 가동, 가장, 가치, 각각, 감소, 강세, 강조, 강화, ...  2020/01/01  0.0   \n",
       "\n",
       "        score  \n",
       "0    0.000000  \n",
       "1    0.000000  \n",
       "2    0.000000  \n",
       "3   -0.001861  \n",
       "4   -0.000937  \n",
       "..        ...  \n",
       "385 -0.007659  \n",
       "386 -0.007631  \n",
       "387 -0.007631  \n",
       "388 -0.007659  \n",
       "389 -0.007576  \n",
       "\n",
       "[390 rows x 4 columns]"
      ]
     },
     "execution_count": 542,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.        , -0.00186128, -0.00093656, -0.00082417, -0.00140614,\n",
       "       -0.00124714, -0.00109727, -0.00098115, -0.00096332, -0.00113766,\n",
       "       -0.00179104, -0.00164801, -0.00157161, -0.00181155, -0.00166536,\n",
       "       -0.00161438, -0.00120414, -0.00157683, -0.00167713, -0.00159271,\n",
       "       -0.00173221, -0.00190613, -0.00185401, -0.00183964, -0.00186861,\n",
       "       -0.00183254, -0.00182549, -0.00189094, -0.00189851, -0.001876  ,\n",
       "       -0.0018468 , -0.00180466, -0.00177763, -0.00176441, -0.00179783,\n",
       "       -0.00175788, -0.00174495, -0.001771  , -0.00181849, -0.00188344,\n",
       "       -0.00804376, -0.00810636, -0.00807494, -0.00801282, -0.00798212,\n",
       "       -0.00795165, -0.00789141, -0.00786164, -0.00792142, -0.00783208,\n",
       "       -0.00780275, -0.00777363, -0.00774473, -0.00768758, -0.00771605,\n",
       "       -0.00765931, -0.00763126, -0.00757576, -0.00760341, -0.00754831,\n",
       "       -0.00752106])"
      ]
     },
     "execution_count": 544,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dic.score.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
